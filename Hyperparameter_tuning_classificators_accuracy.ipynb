{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hyperparameter_tuning_classificators_accuracy.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPKaC4ua16Sto52qwGbE3IW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alonsocampana/fire-montesinho/blob/main/Hyperparameter_tuning_classificators_accuracy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bvtYKt_jtGDo",
        "outputId": "9ac7b8e3-2faa-490b-c8b3-fa2d3bc07dac"
      },
      "source": [
        "#pip install scikit-optimize"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting scikit-optimize\n",
            "  Downloading scikit_optimize-0.8.1-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[?25l\r\u001b[K     |███▎                            | 10 kB 24.9 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 20 kB 31.0 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 30 kB 36.9 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 40 kB 37.8 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 51 kB 33.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 61 kB 33.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 71 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 81 kB 34.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 92 kB 31.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 101 kB 9.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (1.0.1)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (1.4.1)\n",
            "Collecting pyaml>=16.9\n",
            "  Downloading pyaml-21.8.3-py2.py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (1.19.5)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from pyaml>=16.9->scikit-optimize) (3.13)\n",
            "Installing collected packages: pyaml, scikit-optimize\n",
            "Successfully installed pyaml-21.8.3 scikit-optimize-0.8.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DilDrnd9qcTl"
      },
      "source": [
        "import sys\n",
        "sys.path.insert(1, './imports')\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pickle\n",
        "from exploratory_analysis import *\n",
        "from preprocessing import *\n",
        "from model_selection import *\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.linear_model import Lasso\n",
        "import skopt\n",
        "pd.options.display.max_rows = 30\n",
        "from skopt.space import Integer\n",
        "from skopt.space import Real\n",
        "from skopt.space import Categorical\n",
        "from skopt.utils import use_named_args\n",
        "from skopt import gp_minimize\n",
        "from skopt import forest_minimize"
      ],
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-txjQ-1tPT3"
      },
      "source": [
        "# Searching the model space for most accurate (jan-may)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adaWlMbqq8_R"
      },
      "source": [
        "search_space = list()\n",
        "search_space.append(Real(1e-6, 100.0, 'log-uniform', name='C'))\n",
        "search_space.append(Categorical(['rbf'], name='kernel'))\n",
        "search_space.append(Integer(1, 5, name='degree'))\n",
        "search_space.append(Real(1e-6, 100.0, 'log-uniform', name='gamma'))\n",
        "@use_named_args(search_space)\n",
        "def evaluate_model(**params):\n",
        "\t# configure the model with specific hyperparameters\n",
        "\tmodel = SVC()\n",
        "\tmodel.set_params(**params)\n",
        "\t# define test harness\n",
        "\tcv = RepeatedStratifiedKFold(n_splits=10, n_repeats=5, random_state=3558)\n",
        "\t# calculate 5-fold cross validation\n",
        "\tresult = cross_val_score(model, X, y, cv=cv, n_jobs=-1, scoring='accuracy')\n",
        "\t# calculate the mean of the scores\n",
        "\testimate = np.mean(result)\n",
        "\t# convert from a maximizing score to a minimizing score\n",
        "\treturn 1.0 - estimate"
      ],
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TsVrangtIbR"
      },
      "source": [
        "fires = pd.read_csv(\"fires_jan_may.csv\")"
      ],
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YO2tSiGJuUqm"
      },
      "source": [
        "X, y = fires.drop([\"area\", \"area_bool\", \"index\", \"index.1\", \"index.2\", 'Unnamed: 0', 'index'], axis=1), fires[\"area_bool\"]"
      ],
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4zBvQwKuZRt",
        "outputId": "4820594c-b273-400e-dac1-423468084998"
      },
      "source": [
        "result = gp_minimize(evaluate_model, search_space)"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.7/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.7/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.7/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.7/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.7/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.7/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.7/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZD1NnlXAwVjU",
        "outputId": "4f11c49b-d478-4e3e-edcb-37af201eb9af"
      },
      "source": [
        "print(result.x)\n",
        "print(result.fun)"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[100.0, 'rbf', 5, 0.002652859881404326]\n",
            "0.29055555555555557\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oa981WG6tZI2"
      },
      "source": [
        "# Searching Regression with smaller loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpGcfXSWtldr"
      },
      "source": [
        "## Lasso"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0eoT4Xq6Hyn"
      },
      "source": [
        "filter_nonzero = fires[\"area_bool\"] == 1\n",
        "X, y = fires[filter_nonzero].drop([\"area\", \"area_bool\", \"index\", \"index.1\", \"index.2\", 'Unnamed: 0', 'index'], axis=1), fires[filter_nonzero][\"area\"]"
      ],
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYpiHbqIpszg"
      },
      "source": [
        "losses_lasso_df = hyperpar_grid_lasso(X, y, degrees = [1, 2, 3, 4])"
      ],
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "iUi4D0EUr-ky",
        "outputId": "f84dff9a-0c49-41f4-e84e-7c8c06564c9d"
      },
      "source": [
        "losses_lasso_df"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0.100000</th>\n",
              "      <th>0.143845</th>\n",
              "      <th>0.206914</th>\n",
              "      <th>0.297635</th>\n",
              "      <th>0.428133</th>\n",
              "      <th>0.615848</th>\n",
              "      <th>0.885867</th>\n",
              "      <th>1.274275</th>\n",
              "      <th>1.832981</th>\n",
              "      <th>2.636651</th>\n",
              "      <th>3.792690</th>\n",
              "      <th>5.455595</th>\n",
              "      <th>7.847600</th>\n",
              "      <th>11.288379</th>\n",
              "      <th>16.237767</th>\n",
              "      <th>23.357215</th>\n",
              "      <th>33.598183</th>\n",
              "      <th>48.329302</th>\n",
              "      <th>69.519280</th>\n",
              "      <th>100.000000</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>280.532749</td>\n",
              "      <td>278.108662</td>\n",
              "      <td>277.926243</td>\n",
              "      <td>277.926243</td>\n",
              "      <td>277.926243</td>\n",
              "      <td>277.926243</td>\n",
              "      <td>277.926243</td>\n",
              "      <td>277.926243</td>\n",
              "      <td>277.926243</td>\n",
              "      <td>277.926243</td>\n",
              "      <td>277.926243</td>\n",
              "      <td>277.926243</td>\n",
              "      <td>277.926243</td>\n",
              "      <td>277.926243</td>\n",
              "      <td>277.926243</td>\n",
              "      <td>277.926243</td>\n",
              "      <td>277.926243</td>\n",
              "      <td>277.926243</td>\n",
              "      <td>277.926243</td>\n",
              "      <td>277.926243</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>280.532749</td>\n",
              "      <td>278.108662</td>\n",
              "      <td>277.926243</td>\n",
              "      <td>277.926243</td>\n",
              "      <td>277.926243</td>\n",
              "      <td>277.926243</td>\n",
              "      <td>277.926243</td>\n",
              "      <td>277.926243</td>\n",
              "      <td>277.926243</td>\n",
              "      <td>277.926243</td>\n",
              "      <td>277.926243</td>\n",
              "      <td>277.926243</td>\n",
              "      <td>277.926243</td>\n",
              "      <td>277.926243</td>\n",
              "      <td>277.926243</td>\n",
              "      <td>277.926243</td>\n",
              "      <td>277.926243</td>\n",
              "      <td>277.926243</td>\n",
              "      <td>277.926243</td>\n",
              "      <td>277.926243</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>280.532749</td>\n",
              "      <td>278.108662</td>\n",
              "      <td>277.926243</td>\n",
              "      <td>277.926243</td>\n",
              "      <td>277.926243</td>\n",
              "      <td>277.926243</td>\n",
              "      <td>277.926243</td>\n",
              "      <td>277.926243</td>\n",
              "      <td>277.926243</td>\n",
              "      <td>277.926243</td>\n",
              "      <td>277.926243</td>\n",
              "      <td>277.926243</td>\n",
              "      <td>277.926243</td>\n",
              "      <td>277.926243</td>\n",
              "      <td>277.926243</td>\n",
              "      <td>277.926243</td>\n",
              "      <td>277.926243</td>\n",
              "      <td>277.926243</td>\n",
              "      <td>277.926243</td>\n",
              "      <td>277.926243</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>280.532749</td>\n",
              "      <td>278.108662</td>\n",
              "      <td>277.926243</td>\n",
              "      <td>277.926243</td>\n",
              "      <td>277.926243</td>\n",
              "      <td>277.926243</td>\n",
              "      <td>277.926243</td>\n",
              "      <td>277.926243</td>\n",
              "      <td>277.926243</td>\n",
              "      <td>277.926243</td>\n",
              "      <td>277.926243</td>\n",
              "      <td>277.926243</td>\n",
              "      <td>277.926243</td>\n",
              "      <td>277.926243</td>\n",
              "      <td>277.926243</td>\n",
              "      <td>277.926243</td>\n",
              "      <td>277.926243</td>\n",
              "      <td>277.926243</td>\n",
              "      <td>277.926243</td>\n",
              "      <td>277.926243</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   0.100000    0.143845    0.206914    ...  48.329302   69.519280   100.000000\n",
              "1  280.532749  278.108662  277.926243  ...  277.926243  277.926243  277.926243\n",
              "2  280.532749  278.108662  277.926243  ...  277.926243  277.926243  277.926243\n",
              "3  280.532749  278.108662  277.926243  ...  277.926243  277.926243  277.926243\n",
              "4  280.532749  278.108662  277.926243  ...  277.926243  277.926243  277.926243\n",
              "\n",
              "[4 rows x 20 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NeG_QnATJm4W"
      },
      "source": [
        "## Ridge"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Or5BZ1poIk8J"
      },
      "source": [
        "def crossval_ridge(X, y, degree, alpha):\n",
        "    \"\"\"\n",
        "        Uses k-fold crossval to estimate the loss associated to a given degree of a polynomial feature map, and alpha regularization value.\n",
        "    \"\"\"\n",
        "    X_temp = X.copy()\n",
        "    featurizer = PolynomialFeatures(degree=degree)\n",
        "    featurizer.fit(X)\n",
        "    X_temp = featurizer.transform(X_temp)\n",
        "    rskf = KFold(n_splits=5, shuffle=True,random_state=3558)\n",
        "    losses = []\n",
        "    n=0\n",
        "    for train_index, test_index in rskf.split(X, y):\n",
        "        X_train, X_test = X_temp[train_index], X_temp[test_index]\n",
        "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "        model = Ridge(alpha=alpha)\n",
        "        n+=1\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "        losses.append(average_squared_loss_from_log(y_pred, y_test))\n",
        "    return sum(losses)/n\n",
        "\n",
        "def hyperpar_grid_ridge(X, y, degrees = [1, 2, 3], min_alpha = -1, max_alpha = 2):\n",
        "    \"\"\"\n",
        "        Uses grid search for estimating the loss associated to different combinations of degrees of the feature map and alpha regularization parameters\n",
        "    \"\"\"\n",
        "    degrees = degrees\n",
        "    alphas = np.logspace(min_alpha, max_alpha, 20)\n",
        "    losses = np.zeros([len(degrees), len(alphas)])\n",
        "    for i, deg in enumerate(degrees):\n",
        "        for j, alpha in enumerate(alphas):\n",
        "            losses[i, j] = crossval_ridge(X, y, deg, alpha)\n",
        "    return pd.DataFrame(losses, index= degrees, columns = alphas)\n",
        "losses_ridge_df = hyperpar_grid_ridge(X, y, degrees = [1, 2, 3, 4])"
      ],
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "hAmJHvbPJPKM",
        "outputId": "5eb8260f-b313-4484-dd34-2e9e97a4a12a"
      },
      "source": [
        "losses_ridge_df"
      ],
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0.100000</th>\n",
              "      <th>0.143845</th>\n",
              "      <th>0.206914</th>\n",
              "      <th>0.297635</th>\n",
              "      <th>0.428133</th>\n",
              "      <th>0.615848</th>\n",
              "      <th>0.885867</th>\n",
              "      <th>1.274275</th>\n",
              "      <th>1.832981</th>\n",
              "      <th>2.636651</th>\n",
              "      <th>3.792690</th>\n",
              "      <th>5.455595</th>\n",
              "      <th>7.847600</th>\n",
              "      <th>11.288379</th>\n",
              "      <th>16.237767</th>\n",
              "      <th>23.357215</th>\n",
              "      <th>33.598183</th>\n",
              "      <th>48.329302</th>\n",
              "      <th>69.519280</th>\n",
              "      <th>100.000000</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>388.470804</td>\n",
              "      <td>320.782362</td>\n",
              "      <td>279.571537</td>\n",
              "      <td>256.553774</td>\n",
              "      <td>246.074190</td>\n",
              "      <td>243.858677</td>\n",
              "      <td>246.481037</td>\n",
              "      <td>251.286181</td>\n",
              "      <td>256.488693</td>\n",
              "      <td>261.150673</td>\n",
              "      <td>264.960824</td>\n",
              "      <td>267.946515</td>\n",
              "      <td>270.256650</td>\n",
              "      <td>272.049249</td>\n",
              "      <td>273.450901</td>\n",
              "      <td>274.551311</td>\n",
              "      <td>275.411837</td>\n",
              "      <td>276.076932</td>\n",
              "      <td>276.582586</td>\n",
              "      <td>276.960276</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>300.646985</td>\n",
              "      <td>295.885875</td>\n",
              "      <td>290.318361</td>\n",
              "      <td>284.214510</td>\n",
              "      <td>278.019636</td>\n",
              "      <td>272.281350</td>\n",
              "      <td>267.529248</td>\n",
              "      <td>264.158257</td>\n",
              "      <td>262.351762</td>\n",
              "      <td>262.048662</td>\n",
              "      <td>262.957732</td>\n",
              "      <td>264.637804</td>\n",
              "      <td>266.634457</td>\n",
              "      <td>268.605841</td>\n",
              "      <td>270.369173</td>\n",
              "      <td>271.868846</td>\n",
              "      <td>273.117626</td>\n",
              "      <td>274.150806</td>\n",
              "      <td>275.002338</td>\n",
              "      <td>275.697703</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>281.708523</td>\n",
              "      <td>281.211956</td>\n",
              "      <td>280.532915</td>\n",
              "      <td>279.623202</td>\n",
              "      <td>278.438100</td>\n",
              "      <td>276.951131</td>\n",
              "      <td>275.175381</td>\n",
              "      <td>273.186299</td>\n",
              "      <td>271.134916</td>\n",
              "      <td>269.238423</td>\n",
              "      <td>267.741554</td>\n",
              "      <td>266.854679</td>\n",
              "      <td>266.686652</td>\n",
              "      <td>267.200680</td>\n",
              "      <td>268.223895</td>\n",
              "      <td>269.516716</td>\n",
              "      <td>270.862365</td>\n",
              "      <td>272.121267</td>\n",
              "      <td>273.232425</td>\n",
              "      <td>274.185145</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>274.999590</td>\n",
              "      <td>274.899425</td>\n",
              "      <td>274.758012</td>\n",
              "      <td>274.559954</td>\n",
              "      <td>274.285666</td>\n",
              "      <td>273.911752</td>\n",
              "      <td>273.413048</td>\n",
              "      <td>272.767552</td>\n",
              "      <td>271.965307</td>\n",
              "      <td>271.021133</td>\n",
              "      <td>269.988411</td>\n",
              "      <td>268.967631</td>\n",
              "      <td>268.101407</td>\n",
              "      <td>267.549417</td>\n",
              "      <td>267.443389</td>\n",
              "      <td>267.835155</td>\n",
              "      <td>268.666347</td>\n",
              "      <td>269.787318</td>\n",
              "      <td>271.019644</td>\n",
              "      <td>272.219692</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   0.100000    0.143845    0.206914    ...  48.329302   69.519280   100.000000\n",
              "1  388.470804  320.782362  279.571537  ...  276.076932  276.582586  276.960276\n",
              "2  300.646985  295.885875  290.318361  ...  274.150806  275.002338  275.697703\n",
              "3  281.708523  281.211956  280.532915  ...  272.121267  273.232425  274.185145\n",
              "4  274.999590  274.899425  274.758012  ...  269.787318  271.019644  272.219692\n",
              "\n",
              "[4 rows x 20 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 164
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYj2IQDmJzyZ"
      },
      "source": [
        "## Gradient boost regressor with polynomial features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EL6Y6i4NJy0I",
        "outputId": "80cc53e0-e023-4793-b5b3-2dfaccc39b21"
      },
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "def gbr_score(X, y, degree, learning_rate, n_estimators):\n",
        "  poly = PolynomialFeatures(degree=degree)\n",
        "  poly.fit(X)\n",
        "  X_temp = poly.transform(X)\n",
        "  rskf = KFold(n_splits=5, shuffle=True,random_state=3558)\n",
        "  losses = []\n",
        "  n=0\n",
        "  for train_index, test_index in rskf.split(X, y):\n",
        "    n += 1\n",
        "    X_train, X_test = X_temp[train_index], X_temp[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "    model = GradientBoostingRegressor(learning_rate = learning_rate, n_estimators = n_estimators)\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    losses.append(average_squared_loss_from_log(y_pred, y_test))\n",
        "  return sum(losses)/n\n",
        "gbr_score(X, y, 2, 0.1, 200)\n",
        "\n",
        "def hyper_opt_gbr(X, y):\n",
        "  degrees, learning_rates, n_estimatorss = [1, 2, 3], np.linspace(0.05, 0.6, 5), [20, 50, 100]\n",
        "  min_loss = 10000\n",
        "  for deg in degrees:\n",
        "    for lr in learning_rates:\n",
        "      for n_estimator in n_estimatorss:\n",
        "        temp_loss = gbr_score(X, y, deg, lr, n_estimator)\n",
        "        if temp_loss < min_loss:\n",
        "          min_loss = temp_loss\n",
        "          min_deg = deg\n",
        "          min_lr = lr\n",
        "          min_n_estimator = n_estimator\n",
        "  return {\"loss\":min_loss, \"deg\": min_deg, \"lr\":min_lr, \"n_estimators\":min_n_estimator}\n",
        "\n",
        "hyper_opt_gbr(X, y)"
      ],
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'deg': 3, 'loss': 227.0846601173799, 'lr': 0.1875, 'n_estimators': 20}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 170
        }
      ]
    }
  ]
}